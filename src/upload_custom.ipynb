{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.cognitiveservices.vision.customvision.training import CustomVisionTrainingClient\n",
    "from azure.cognitiveservices.vision.customvision.prediction import CustomVisionPredictionClient\n",
    "from azure.cognitiveservices.vision.customvision.training.models import ImageFileCreateBatch, ImageFileCreateEntry, Region\n",
    "from msrest.authentication import ApiKeyCredentials\n",
    "import os, time, uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "with open('../config.yaml') as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENDPOINT = f\"https://{config['custom_vision']['endpoint']}/\"\n",
    "training_key = config[\"custom_vision\"][\"training_key\"]\n",
    "prediction_key = config[\"custom_vision\"][\"prediction_key\"]\n",
    "prediction_resource_id = config[\"custom_vision\"][\"prediction_resource_id\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "publish_iteration_name = \"FireNet\"\n",
    "\n",
    "credentials = ApiKeyCredentials(in_headers={\"Training-key\": training_key})\n",
    "trainer = CustomVisionTrainingClient(ENDPOINT, credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not config[\"project_id\"]:\n",
    "    # Create a new project\n",
    "    print(\"Creating project...\")\n",
    "    obj_detection_domain = next(\n",
    "        domain\n",
    "        for domain in trainer.get_domains()\n",
    "        if domain.type == \"ObjectDetection\" and domain.name == \"General\"\n",
    "    )\n",
    "\n",
    "    # Use uuid to avoid project name collisions.\n",
    "    project = trainer.create_project(\n",
    "        str(uuid.uuid4()),\n",
    "        domain_id=obj_detection_domain.id,\n",
    "        classification_type=\"Multiclass\",\n",
    "    )\n",
    "else:\n",
    "    project = trainer.get_project(config[\"project_id\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload and tag images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "local_path = Path(\"../data\")\n",
    "datasets = [e for e in local_path.iterdir() if e.is_dir()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add tags to the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images and labels...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:00<00:00, 334.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading latest batch 22...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for data_path in datasets:\n",
    "    images_path = data_path / \"Images\"\n",
    "    df = pd.read_pickle(data_path / \"object_detection.pkl\")\n",
    "\n",
    "    tags = {}\n",
    "    for az_tag in trainer.get_tags(project.id):\n",
    "        tags[az_tag.name] = az_tag\n",
    "    for tag_name in df.tag.unique():\n",
    "        if tag_name not in tags:\n",
    "            tags[tag_name] = trainer.create_tag(project.id, tag_name)\n",
    "    len(tags)\n",
    "\n",
    "    batch_size = config[\"upload_batch_size\"]\n",
    "    tagged_images_with_regions = []\n",
    "\n",
    "    print(\"Loading images and labels...\")\n",
    "\n",
    "    images = df.filename.unique()\n",
    "    i = 0\n",
    "    for file_name in tqdm(images):\n",
    "        i += 1\n",
    "\n",
    "        rows = df.where(df.filename == file_name).dropna()\n",
    "        regions = []\n",
    "        for _, row in rows.iterrows():\n",
    "            regions.append(\n",
    "                Region(\n",
    "                    tag_id=tags[row[\"tag\"]].id,\n",
    "                    left=row[\"left\"],\n",
    "                    top=row[\"top\"],\n",
    "                    width=row[\"width\"],\n",
    "                    height=row[\"height\"],\n",
    "                )\n",
    "            )\n",
    "\n",
    "        with open(images_path / file_name, mode=\"rb\") as image_contents:\n",
    "            tagged_images_with_regions.append(\n",
    "                ImageFileCreateEntry(\n",
    "                    name=file_name, contents=image_contents.read(), regions=regions\n",
    "                )\n",
    "            )\n",
    "\n",
    "        if i % batch_size == 0:\n",
    "            print(f\"Uploading image batch {i} ...\")\n",
    "            upload_result = trainer.create_images_from_files(\n",
    "                project.id, ImageFileCreateBatch(images=tagged_images_with_regions)\n",
    "            )\n",
    "            tagged_images_with_regions = []\n",
    "            if not upload_result.is_batch_successful:\n",
    "                errors = False\n",
    "                for image in upload_result.images:\n",
    "                    if image.status != \"OK\" and image.status != \"OKDuplicate\":\n",
    "                        errors = True\n",
    "                        print(f\"Image {image.source_url}: {image.status}\")\n",
    "                if errors:\n",
    "                    print(f\"Image batch {i} upload failed.\")\n",
    "                    break\n",
    "\n",
    "    if len(tagged_images_with_regions) > 0:\n",
    "        print(f\"Uploading latest batch {i}...\")\n",
    "        upload_result = trainer.create_images_from_files(\n",
    "            project.id, ImageFileCreateBatch(images=tagged_images_with_regions)\n",
    "        )\n",
    "        tagged_images_with_regions = []\n",
    "        if not upload_result.is_batch_successful:\n",
    "            errors = False\n",
    "            for image in upload_result.images:\n",
    "                if image.status != \"OK\" and image.status != \"OKDuplicate\":\n",
    "                    errors = True\n",
    "                    print(f\"Image {image.source_url}: {image.status}\")\n",
    "            if errors:\n",
    "                print(f\"Latest Image batch upload failed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding images"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "98a0b6d604a978f528107cf56ed5adf621efabd1f2a3cefd56fba0ab577db355"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('azure-firenet': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
